# -*- coding: utf-8 -*-
"""submission_DS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cQjXSFwUSjYWicZoTr59_GJbrkZgIV13

# Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Edutech

- Nama: Bagas Aqmal Febrianto
- Email: bagasaqmal70@gmail.com
- Id Dicoding: Bagas Aqmal Febrianto

## Persiapan

### Menyiapkan library yang dibutuhkan
"""

import pandas as pd

"""### Menyiapkan data yang akan digunakan"""

# from google.colab import drive
# drive.mount('/content/drive')

df = pd.read_csv('employee_data.csv')
df

"""## Data Understanding

**Melihat informasi dataset**
"""

df.info()

"""Berikut adalah deskripsi dari fitur pada dataset perusahaan :
- EmployeeId: ID Karyawan

- Attrition: Apakah karyawan keluar? (0 = Tidak, 1 = Ya)

- Age: Usia karyawan

- BusinessTravel: Frekuensi perjalanan bisnis

- DailyRate: Gaji harian

- Department: Departemen tempat bekerja

- DistanceFromHome: Jarak dari rumah ke tempat kerja (dalam km)

- Education: Tingkat pendidikan (1 = Di bawah perguruan tinggi, 2 = Perguruan tinggi, 3 = Sarjana, 4 = Magister, 5 = Doktor)

- EducationField: Bidang pendidikan

- EnvironmentSatisfaction: Kepuasan terhadap lingkungan kerja (1 = Rendah, 2 = Sedang, 3 = Tinggi, 4 = Sangat Tinggi)

- Gender: Jenis kelamin karyawan

- HourlyRate: Gaji per jam

- JobInvolvement: Tingkat keterlibatan kerja (1 = Rendah, 2 = Sedang, 3 = Tinggi, 4 = Sangat Tinggi)

- JobLevel: Level pekerjaan (1 hingga 5)

- JobRole: Peran pekerjaan

- JobSatisfaction: Kepuasan kerja (1 = Rendah, 2 = Sedang, 3 = Tinggi, 4 = Sangat Tinggi)

- MaritalStatus: Status pernikahan

- MonthlyIncome: Gaji bulanan

- MonthlyRate: Tarif bulanan

- NumCompaniesWorked: Jumlah perusahaan yang pernah ditempati

- Over18: Apakah berusia di atas 18 tahun?

- OverTime: Apakah lembur?

- PercentSalaryHike: Persentase kenaikan gaji tahun lalu

- PerformanceRating: Penilaian kinerja (1 = Rendah, 2 = Baik, 3 = Sangat Baik, 4 = Luar Biasa)

- RelationshipSatisfaction: Kepuasan terhadap hubungan kerja (1 = Rendah, 2 = Sedang, 3 = Tinggi, 4 = Sangat Tinggi)

- StandardHours: Jam kerja standar

- StockOptionLevel: Level opsi saham

- TotalWorkingYears: Total tahun bekerja

- TrainingTimesLastYear: Jumlah pelatihan yang diikuti tahun lalu

- WorkLifeBalance: Keseimbangan kerja dan kehidupan (1 = Rendah, 2 = Baik, 3 = Sangat Baik, 4 = Luar Biasa)

- YearsAtCompany: Lama bekerja di perusahaan (dalam tahun)

- YearsInCurrentRole: Lama menjabat pada peran saat ini (dalam tahun)

- YearsSinceLastPromotion: Lama sejak promosi terakhir (dalam tahun)

- YearsWithCurrManager: Lama bekerja dengan manajer saat ini (dalam tahun)

**Melihat statistik deskriptif dataset**
"""

df.describe().T

df.describe()

"""Berdasarkan analisis statistik deskriptif diaatas, tampak bahwa tidak terdapat data yang tidak masuk akal. Namun jika diperhatikan pada jumlah Attrition, terdapat data yang kosong.

Kita dapat memastikan nilai yang kosong pada cara selanjutnya.

**Memeriksa Nilai Kosong**
"""

df.isnull().sum()

"""Terdapat 412 baris data yang memiliki nilai kosong (NaN) pada kolom Attrition.




Kita dapat mengisi nilai kosong tersebut dengan 0, dengan asumsi bahwa pertanyaan "Apakah karyawan keluar?" hanya dijawab oleh karyawan yang memang keluar dari perusahaan. Sehingga, jika nilai tersebut kosong, dapat diasumsikan bahwa karyawan tersebut tidak keluar (Attrition = 0).
"""

df = df.dropna(subset='Attrition')
df['Attrition'].isnull().sum()

"""Tampak bahwa tidak terdapat nilai NaN pada kolom Attrition

**Memeriksa DUplikasi Data**
"""

df.duplicated(subset='EmployeeId').sum()

"""Pemeriksaan nilai duplikat dilihat berdasarkan kolom EmployeeId, tampak bahwa tidak terdapat nilai yang duplikat.

### Exploratory Data Analysis
"""

df_eda = df.copy()

"""Lakukan copy terhadap data, hal ini dilakukan agar perubahan yang terjadi pada proeses Eda tidak mempengaruhi proses selanjutnya.

#### **Univariate Analysis**
"""

df_eda.head()

"""**Demografi Pekerja**"""

attrition_counts = df_eda['Attrition'].value_counts()
attrition_counts

"""**Jumalah Pekerja berdasarkan Attrition**"""

import matplotlib.pyplot as plt


# Plot
plt.figure(figsize=(6, 4))
attrition_counts.plot(kind='bar', color=['skyblue', 'salmon'])
plt.title('Jumlah Pekerja Berdasarkan Attrition')
plt.xlabel('Attrition')
plt.ylabel('Jumlah Karyawan')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Tampak bahwa jumlah karyawan yang dikatakan mengundurkan diri 2% lebih rendah dibandingkan karyawan yang memilih untuk tetap. Hal ini juga dapat dikatakan Proporsi yang tidak seimbang, mengingat fitur ini nantinya akan dijadikan target pada tahap Modeling.

**Jumlah Pekerja berdasarkan gener**
"""

df_gender = df_eda['Gender'].value_counts()
df_gender

colors = ['#66b3ff', '#ff9999']
df_gender.plot(kind='pie',
               autopct='%1.1f%%',
               startangle=90,
               colors=colors,
               labels=df_gender.index,
               ylabel='',
               title = 'Jumlah Pekerja Berdasarkan Jenis Kelamin')
plt.show('equal')
plt.tight_layout()
plt.show()

"""Tampak bahwa pekerja pria / laki-laki cenderung 60% lebih banyak dibandingkan dengan wanita.

**Jumlah pekerja diatas 18+**
"""

df_eda['Over18'].value_counts()

"""Tampak bahwa seluruh pekerja pada perusahaan berusia diatas 18+.

**Jumlah Pekerja berdasarkan tingkat pendidikan**
"""

education_mapping = {
    1: 'Di bawah perguruan tinggi',
    2: 'Perguruan tinggi',
    3: 'Sarjana',
    4: 'Magister',
    5: 'Doktor'
}

df_eda['Education'] = df_eda['Education'].map(education_mapping)

df_edu = df_eda['Education'].value_counts()

plt.figure(figsize=(10, 8))
df_edu.plot(kind='bar')
plt.title('Jumlah Pekerja Berdasarkan Tingkat Pendidikan')
plt.xlabel('Tingkat Pendidikan')
plt.ylabel('Jumlah Pekerja')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Jumlah karyawan berdasrakan tingkat pendidikan, dapat dilihat tingkat Sarjana menjadi tingkat pendidikan dengan jumlah pekerja terbanyak yang selanjutnya diikuti oleh Tingkat Magister.

**Jumlah Pekerja berdasarkan Departemen**
"""

df_dept = df_eda['Department'].value_counts()
df_dept

plt.figure(figsize=(10, 8))
df_dept.plot(kind='bar')
plt.title('Jumlah Pekerja Berdasarkan Departemen')
plt.xlabel('Departemen')
plt.ylabel('Jumlah Pekerja')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Berdasarkan visualisasi diatas tampak bahwa Departemen R&D memiliki jumlah pekerja yang lebih banyak dari pada kedua departemen lainnya, dimana departemen dengan jumlah pekerja paling sedikit adalah HR.

**Jumlah Pekerja yang mengambil lembur**
"""

df_eda['OverTime'].value_counts()

# overtime_map = {
#     No: 'Tidak',
#     Yes: 'Ya'
# }

# df_eda['OverTime'] = df_eda['OverTime'].map(overtime_map)

df_overtime = df_eda['OverTime'].value_counts()

df_overtime

plt.figure(figsize=(6, 4))
df_overtime.plot(kind='bar', color=['skyblue', 'salmon'])
plt.title('Jumlah Pekerja Mengambil Lembur')
plt.xlabel('Status lembur pekerja')
plt.ylabel('Jumlah Pekerja')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Jumlah karyawan yang mengambil lember cenderung lebih sedikit dari pada karyawan yang tidak mengambil lembur.

**Jumlah karyawan untuk setiap persentasi kenaikan gaji**
"""

df_persen_gaji = df_eda['PercentSalaryHike'].value_counts()

df_persen_gaji.plot(kind='bar')
plt.title('Distribusi Persentase Kenaikan Gaji')
plt.xlabel('Persentase Kenaikan Gaji')
plt.ylabel('Jumlah Karyawan')
plt.xticks(rotation=90)
plt.grid(axis='y', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

"""**JUmlah Pekerja berdasarkan tingkat keterlibatannya**"""

kuesioner_map = {
    1: 'Rendah',
    2: 'Sedang',
    3: 'Tinggi',
    4: 'Sangat Tinggi'
}

df_eda['JobInvolvement'] = df_eda['JobInvolvement'].map(kuesioner_map)

df_keterlibatan = df_eda['JobInvolvement'].value_counts()
df_keterlibatan

plt.figure(figsize=(10,6))
df_keterlibatan.plot(kind='bar')
plt.title('Jumlah Pekerja Berdasarkan Tingkat Keterlibatannya')
plt.xlabel('Tingkat Keterlibatan')
plt.ylabel('Jumlah Pekerja')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Berdasarkan bar chart di atas, tingkat keterlibatan pekerja paling dominan berada pada kategori Tinggi, dengan jumlah lebih dari 800 karyawan.

**Jumlah pekerja berdasarkan keseimbangan kerja dan kehidupan**
"""

df_eda['WorkLifeBalance'] = df_eda['WorkLifeBalance'].map(kuesioner_map)

df_balance = df_eda['WorkLifeBalance'].value_counts()
df_balance

plt.figure(figsize=(10,6))
df_balance.plot(kind='bar')
plt.title('Jumlah Pekerja Berdasarkan Kualitas Kinerja')
plt.xlabel('Kualitas Kinerja')
plt.ylabel('Jumlah Pekerja')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Berdasarkan visualisasi diatas, Keseimbangan antara kerja dan kehidupan para pekerja banyak yang dikatakan tinggi.

**Distribusi jawaban pekerja terhadap tingkat Kepuasan dalam bekerja**
"""

col_kuesioner = ['EnvironmentSatisfaction', 'JobSatisfaction', 'RelationshipSatisfaction']

col_label = ['Kepuasan terhadap lingkungan','Kepuasan terhadap Pekerjaan','Kepuasan terhadap hubungan pekerjaan']

for col, label in zip(col_kuesioner, col_label):
    df_eda[col] = df_eda[col].map(kuesioner_map)

    value_counts = df_eda[col].value_counts().reindex(kuesioner_map.values())

    value_counts.plot(kind='bar', color='teal', legend=False)
    plt.title(f'Distribusi {label}')
    plt.xlabel('Tingkat Kepuasan')
    plt.ylabel('Jumlah Karyawan')
    plt.xticks(rotation=0)
    plt.grid(axis='y', linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.show()

"""Dari ketiga visualisasi diatas, dapat disimpulkan bahwa kepuasan pekerja terhadap pekerjaan, baik hubungan atau relasi dan juga lingkungan dapat dikatakan baik.

**Jumlah karyawan berdasarkan penilaian kinerja**
"""

performance_map = {
    1: 'Rendah',
    2: 'Baik',
    3: 'Sangat Baik',
    4: 'Luar Biasa'
}

df_eda['PerformanceRating'] = df_eda['PerformanceRating'].map(performance_map)

df_performance = df_eda['PerformanceRating'].value_counts()
df_performance

"""Dapat dilihat bahwa performa rata-rata pekerja dapat dikatakan Sangat baik. Dalam hal ini tidak dilakukan visualisais karena terlihat dari pesebaran nilai tidak ada pekerja yang buruk atau rendah.

#### Bivariate Analysis
"""

df_eda.head()

"""**Perbandingan Gaji pekerja berdasarkan level pekerjaan**"""

df_gaji = df_eda.groupby(by='JobLevel').agg({
    'HourlyRate': 'mean',
    'DailyRate': 'mean',
    'MonthlyRate': 'mean'
}).sort_values(by='MonthlyRate', ascending=False)
df_gaji

plt.figure(figsize=(10, 6))
df_gaji.plot(kind='bar', stacked=True)
plt.title('Perbandingan Gaji Karyawan Berdasarkan Level Pekerjaan')
plt.xlabel('Level Pekerjaan')
plt.ylabel('Rata-rata Gaji')
plt.xticks(rotation=0)
plt.legend()
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""**Hubungan Jumlah Attrition terhadap Gender**"""

df_gender_hub = df_eda.groupby(by=['Gender','Attrition']).agg({
    'EmployeeId': 'count'
})
df_gender_pivot = df_gender_hub.unstack()
df_gender_pivot

df_gender_pivot.plot(kind='bar', color=['skyblue', 'salmon'], stacked=True)
plt.title('Jumlah Karyawan Keluar dan Bertahan berdasarkan Gender')
plt.xlabel('Gender')
plt.ylabel('Jumlah Pekerja')
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Dari visualisasi diatas, tampak bahwa Gender tidak mempengaruhi terhadap terjadinya Attrition, hal ini dikarenakan Perbandingan keluar vs tidak keluar terlihat proporsinya mirip antara gender, meskipun jumlah total pekerja pria memang lebih besar.

**Hubungan Attrition terhadap Tingkat Pendidikan**
"""

df_edu_hub = df_eda.groupby(by=['Education','Attrition']).agg({
    'EmployeeId': 'count'
})
df_edu_hub

df_edu_pivot = df_edu_hub.unstack()
df_edu_pivot

df_edu_pivot.plot(kind='bar', stacked=True, color=['skyblue', 'salmon'])
plt.title('Jumlah Karyawan Bertahan dan Keluar Berdasarkan Pendidikan')
plt.xlabel('Tingkat Pendidikan')
plt.ylabel('Jumlah Karyawan')
plt.legend(title='Attrition', labels=['Bertahan (0)', 'Keluar (1)'])
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Jika diperhatikan pada visualisasi diatas, tampak tidak terlihat keanehan pada data, atau dikatakan normal. Jumlah pekerja keluar sebanding dengan jumlah pekerja berdasarkan karyawan, maka dapat kita katakan bahwa Tidak ad ahubungan antara tingkat pendidikan dengan Pekerja yang keluar.

**Hubungan Attriction terhadap Departemen**
"""

df_dept_hub = df_eda.groupby(by=['Department','Attrition']).agg({
    'EmployeeId': 'count'
})

df_dept_pivot = df_dept_hub.unstack()
df_dept_pivot

df_dept_pivot.plot(kind='bar', stacked=True, color=['skyblue', 'salmon'])
plt.title('Jumlah Karyawan Bertahan dan Keluar Berdasarkan Departemen')
plt.xlabel('Departemen')
plt.ylabel('Jumlah Karyawan')
plt.legend(title='Attrition', labels=['Bertahan (0)', 'Keluar (1)'])
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Dari visualisasi diatas, dapat kita ambil kesimpulan bahwa tidak adanya hubungan antara Depertemen dengan kejadian pekerja yang keluar. Hal ini karena jumlah untuk setiap pekerja yang keluar di setiap departemen sebanding dengan jumlah pekerja di setiap departemen.

**Hubungan antara tingkat keterlibatan pekerja dengan Attriction**
"""

df_keterlibatan_hub = df_eda.groupby(by=['JobInvolvement','Attrition']).agg({
    'EmployeeId': 'count'
})
df_keterlibatan_pivot = df_keterlibatan_hub.unstack()
df_keterlibatan_pivot

df_keterlibatan_pivot.plot(kind='bar',stacked=True, color=['skyblue', 'salmon'])
plt.title('Jumlah Karyawan Bertahan dan Keluar Berdasarkan Tingkat Keterlibatan')
plt.xlabel('Tingkat Keterlibatan')
plt.ylabel('Jumlah Karyawan')
plt.legend(title='Attrition', labels=['Bertahan (0)', 'Keluar (1)'])
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Tampak bahwa pekerja dengan tingkat keterlibatan tinggi cenderung terjadinya kasus keluar. Dapat dikatakan bahwa Tingkat keterlibatan menjadi salah satu hal yang mempengaruhi terjadinya Attraction

**Hubungan antara JobLevel dengan Attriction**
"""

df_joblevel_hub = df_eda.groupby(by=['JobLevel','Attrition']).agg({
    'EmployeeId': 'count'
})
df_joblevel_pivot = df_joblevel_hub.unstack()
df_joblevel_pivot

df_joblevel_pivot.plot(kind='bar',stacked=True, color=['skyblue', 'salmon'])
plt.title('Jumlah Karyawan Bertahan dan Keluar Berdasarkan Tingkat Level Pekerjaan')
plt.xlabel('Level Pekerjaan')
plt.ylabel('Jumlah Karyawan')
plt.legend(title='Attrition', labels=['Bertahan (0)', 'Keluar (1)'])
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Dari visualisasi diatas tampak bahwa Tingkat level pekerjaan mempengaruhi terhadap attraction, DImana Level 1 cederung lebih banyak terjadinya kasus keluar dibandingkan level 2 yang jika dilihat jumlah pekerja dikedua level tersebut dapat dikatakan serupa.

**Hubungan antara ROle pekerjaan dengan Attraction**
"""

df_role_hub = df_eda.groupby(by=['JobRole','Attrition']).agg({
    'EmployeeId': 'count'
})
df_role_pivot = df_role_hub.unstack()
df_role_pivot

df_role_pivot.plot(kind='bar',stacked=True, color=['skyblue', 'salmon'])
plt.title('Jumlah Karyawan Bertahan dan Keluar Berdasarkan Role Pekerjaan')
plt.xlabel('Role Pekerjaan')
plt.ylabel('Jumlah Karyawan')
plt.legend(title='Attrition', labels=['Bertahan (0)', 'Keluar (1)'])
plt.xticks(rotation=90)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Tampak bahwa terdapat hubungan antara jobrole dengan kejadian Attraction. Jumlah pekerja yang keluar terlihat tidak sesuai dengan jumlah pekerja disetiap role. Sebagai contoh hampir setengahnya jumlah pekerja di Role Sales yang keluar, hal ini berbeda jauh dengan role Research Director. Sehingga dapat disimpulkan bahwa Role mempengaruhi kejadian keluar atau attraction.

**Hubungan Status pernikahan terhadap kejadian Attraction**
"""

df_marital_hub = df_eda.groupby(by=['MaritalStatus','Attrition']).agg({
    'EmployeeId': 'count'
})
df_marital_pivot = df_marital_hub.unstack()
df_marital_pivot

df_marital_pivot.plot(kind='bar',stacked=True, color=['skyblue', 'salmon'])
plt.title('Jumlah Karyawan Bertahan dan Keluar Berdasarkan Status Pernikahan')
plt.xlabel('Status Pernikahan')
plt.ylabel('Jumlah Karyawan')
plt.legend(title='Attrition', labels=['Bertahan (0)', 'Keluar (1)'])
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

"""Dari visualisasi diatas terlihat bahwa terdapat hubungan antara Status pernikahan terhadap terjadinya Attraction, jika diperhatikan kasus keluar pada status single cenderung dominan dari pada status menikah atau divorced.

**Hubungan antara pekerja lembur dengan Attractiono**
"""

df_overtime_hub = df_eda.groupby(by=['OverTime','Attrition']).agg({
    'EmployeeId': 'count'
})
df_overtime_pivot = df_overtime_hub.unstack()
df_overtime_pivot

df_overtime_pivot.plot(kind='bar',stacked=True, color=['skyblue', 'salmon'])
plt.title('Jumlah Karyawan Bertahan dan Keluar Berdasarkan Pekerja Lembur')
plt.xlabel('Status Pekerja Lembur')
plt.ylabel('Jumlah Karyawan')
plt.legend(title='Attrition', labels=['Bertahan (0)', 'Keluar (1)'])
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

"""Jika diperhatikan pada visualsasi diatas, tampak bahwa pekerja yang mengambil lembur memiliki persentase keluar lebih tinggi dibandingkan yang tidak mengambil lembur. Dapat dikatakan bahwa terdapat hubungan antara Attraction dengan Overtime

**Hubungan antara jawaban kuisioner terhadap kejadian Attraction**
"""

col_kuesioner = ['EnvironmentSatisfaction', 'JobSatisfaction', 'RelationshipSatisfaction']

col_label = ['Kepuasan terhadap lingkungan','Kepuasan terhadap Pekerjaan','Kepuasan terhadap hubungan pekerjaan']

for col, label in zip(col_kuesioner, col_label):

    df_group = df_eda.groupby([col,'Attrition']).agg({
        'EmployeeId': 'count'
    })

    value_counts = df_group.unstack()

    value_counts.plot(kind='bar', color=['skyblue', 'salmon'], legend=True, stacked=True)
    plt.title(f'Distribusi {label}')
    plt.xlabel('Tingkat Kepuasan')
    plt.ylabel('Jumlah Karyawan')
    plt.xticks(rotation=0)
    plt.grid(axis='y', linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.show()

"""Dari ketiga kuesioner yang didapatkan, tampak bahwa tidak terjadi hubungan antara jawaban pekerja dengan kejadian Attaction. Bahwa pesebaran jumlah pekerja yang keluar seimbang untuk setiap jawaban pada kuesioner.

Untuk memastikan keterhubungan variabel kategorik terhadap Terjadinya Attrction, kita akan melihat menggunakan pendekatan lain yang dikenal sebagai Chi-Square.
"""

import pandas as pd
from scipy.stats import chi2_contingency

# Daftar kolom kategorikal yang ingin diuji hubungannya dengan Attrition
df_kategorikal = [
    'Gender',
    'Education',
    'Department',
    'JobInvolvement',
    'JobLevel',
    'JobRole',
    'MaritalStatus',
    'OverTime',
    'PerformanceRating',
    'RelationshipSatisfaction',
    'WorkLifeBalance',
]

# Melakukan uji Chi-Square untuk setiap kolom kategorikal terhadap Attrition
for kolom in df_kategorikal:
    tabel_kontingensi = pd.crosstab(df_eda[kolom], df_eda['Attrition'])
    chi2, p, dof, expected = chi2_contingency(tabel_kontingensi)

    print(f"Uji Chi-Square untuk kolom '{kolom}':")
    print(f"Nilai Chi-Square: {chi2:.4f}")
    print(f"P-value: {p:.4f}")

    if p < 0.05:
        print(f"=> TOLAK hipotesis nol. Terdapat hubungan yang signifikan antara '{kolom}' dan 'Attrition'.")
    else:
        print(f"=> GAGAL menolak hipotesis nol. Tidak terdapat hubungan yang signifikan antara '{kolom}' dan 'Attrition'.")

    print("-" * 60)

"""Tampak bahwa, setelah dilakukan analisis keterhubungan antara fitur Attraction terhadap fitur kategorikal lainnya, dapat dilihaht dari hasil P-Value yang dihasilkan dimana jika P < 0.05 maka dapat dikatakan fitur tersebut berkorelasi. Didapatkan beberapa fitur yang memiliki keterhubungan tinggi, antara lain :
1. Terdapat keterhubungan antara JobInvolvement dengan Attraction.
2. Terdapat keterhubungan antara JobLevel dengan Attraction.
3. Terdapat keterhubungan antara JobRole dengan Attraction.
4. Terdapat keterhubungan antara MaritalStatus dengan Attraction.
5. Terdapat keterhubungan antara Overtime dengan Attraction.
6. Terdapat keterhubungan antara WorkLifeBalance dengan Attraction.

**Analisis Korelasi Attraction terhadap Fitur Numerik**
"""

df_eda.head()

df_eda.info()

pd.set_option('display.max_columns', None)

df_eda.head()

from google.colab import files

df_eda.to_csv('df_eda.csv', index=False)
files.download('df_eda.csv')

import seaborn as sns

kolom_corr = [
    'Attrition',
    'Age',
    'DailyRate',
    'DistanceFromHome',
    'EmployeeCount',
    'HourlyRate',
    'MonthlyIncome',
    'MonthlyRate',
    'YearsAtCompany',
    'NumCompaniesWorked',
    'PercentSalaryHike',
    'StockOptionLevel',
    'TotalWorkingYears',
    'TrainingTimesLastYear',
    'YearsInCurrentRole',
    'YearsSinceLastPromotion',
    'YearsWithCurrManager'
]

# Hitung matriks korelasi
corr_matrix = df_eda[kolom_corr].corr()

# Tampilkan matriks korelasi dalam bentuk heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Matriks Korelasi Antar Variabel Numerik terhadap Attrition')
plt.show()

"""Dari visualisasi diatas tampak bahwa fitur yang mememiliki korelasi terhadap Attraction terdapat 4, yaitu : DistanceFromHome dan MonthlyRate, PercentSalaryHike, NumCompaniesWorked.

Fitur yang dianggap memiliki korelasi diambil berdasarkan besaran nilai yang didapatkan terhadap Attrition, dimana fitur berkorelasi > 0

**Pemeriksaan Outlier Kolom MonthlyRate dan DistanceFromHome**
"""

kolom_boxplot = ['MonthlyRate', 'DistanceFromHome', 'PercentSalaryHike', 'NumCompaniesWorked']

# Tentukan jumlah baris dan kolom untuk subplot
n_rows = 2
n_cols = 2

# Atur ukuran keseluruhan figure
plt.figure(figsize=(20, 11))

# Loop melalui setiap kolom dan subplot
for idx, kolom in enumerate(kolom_boxplot, 1):
    plt.subplot(n_rows, n_cols, idx)
    sns.boxplot(y=df_eda[kolom], color='skyblue')
    plt.title(f'Boxplot - {kolom}')
    plt.ylabel(kolom)

plt.tight_layout()
plt.show()

"""Berdasarkan visualisasi diatas, tampak bahwa kolom NumCompaniesWorked terdapat nilai yang tidak biasa atau melebihi batas atas sehingga dapat kita katakan outlier.

## Data Preparation / Preprocessing

### Remove Outlier
"""

def remove_outliers_iqr(df, columns):
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
    return df

df_cleaned = remove_outliers_iqr(df_eda, ['NumCompaniesWorked'])

"""Fungsi diatas digunakan untuk menangani Outier, Berdasarkan visualisasi sebelumnya outlier ditemukan pada colom NumCompniesWorked. Maka dari itu kita hilangkan pada fitur tsb.

### **Data Selection**

Pada tahap ini kita akan melakukan seleksi fitur berdasasrkan hasil eksplorasi pada fitur sebelumnya. Fitur yang digunakan meliputi, beberapa fitur yang memiliki hubungan terhadap Attraction baik pada fitur kategorial maupun numerikal.
"""

df_selected = df_cleaned[
    ['Attrition', 'DistanceFromHome', 'MonthlyRate', 'JobInvolvement',
     'JobLevel', 'JobRole', 'MaritalStatus', 'OverTime', 'WorkLifeBalance','PercentSalaryHike','NumCompaniesWorked']
]

X = df_selected.drop(columns=['Attrition'])
y = df_selected['Attrition']

"""### **Fitur Encod**

Perubahan nilai fitur menggunakan teknik Label Encod.

Fitur yang akan dilakukan perubahan menggunakan teknik Label Encod adalah JobInvolvement dan WorkLifeBalance. Hal ini dikarenakan kedua fitur tersebut memiliki urutan atau bobot untuk setiap jawabannya.
"""

ordinal_map = {
    'Rendah': 1,
    'Sedang': 2,
    'Tinggi': 3,
    'Sangat Tinggi': 4
}
X['JobInvolvement'] = X['JobInvolvement'].map(ordinal_map)
X['WorkLifeBalance'] = X['WorkLifeBalance'].map(ordinal_map)

"""Proses perubahan nilai fitur dengan one hot encoding dilakukan pda kolom yang tidak memperhatikan urutan seperti JobRole, MaritalStatus, dan Overtime."""

X = pd.get_dummies(X, columns=['JobRole', 'MaritalStatus', 'OverTime'])
X

"""### Train and test Split"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Pembagian data menjadi train dan test dilakukan dengan fungsi train_test_split, dimana pembagian menggunakan skema 0.2 (80:20).

### Standarisasi fitur
"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()


col_scale = ['DistanceFromHome', 'MonthlyRate', 'JobInvolvement', 'JobLevel', 'WorkLifeBalance','PercentSalaryHike','NumCompaniesWorked']
X_train_scaled[col_scale] = scaler.fit_transform(X_train[col_scale])
X_test_scaled[col_scale] = scaler.transform(X_test[col_scale])

"""Untuk menyamakan skala antar fitur numerik, dilakukan standarisasi menggunakan fungsi StandarScaler dari library sklearn. Standarisasi dilakukan pada fitur : 'DistanceFromHome', 'MonthlyRate', 'JobInvolvement', 'JobLevel', 'WorkLifeBalance','PercentSalaryHike','NumCompaniesWorked'

### Smote
"""

from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42, k_neighbors=5)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)

print("Distribusi sebelum SMOTE:")
print(y_train.value_counts())

print("\nDistribusi setelah SMOTE:")
print(pd.Series(y_train_resampled).value_counts())

"""Pada bagian ini akan dilakukan penyamaan jumlah berdasarkan target. Jika diperhatikan sebelumnya, Jumlah data yang memiliki target 1 pada fitur Attrition, cenderung lebih sedikit dan nilai 0 mendominasi data.

Untuk menyamakan distribusi data ini, dilakukan menggunakan teknik smote. Tampak bahwa data terlihat lebih ideal dan sama distribusinya setelah dilakukan teknik smote.

## Modeling

Proses modeling dilakukan menggunakan 4 Algoritma.
1. Support Vector machine
2. Random Forest
3. Naive Bayes
4. XGBoost
"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import xgboost as xgb

"""### Random Forest"""

rf = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5, min_samples_leaf=2)
rf.fit(X_train_resampled, y_train_resampled)
train_acc_rf = accuracy_score(y_train_resampled, rf.predict(X_train_resampled))
test_acc_rf = accuracy_score(y_test, rf.predict(X_test))

"""### SVM"""

svm = SVC(kernel='linear', C=1)
svm.fit(X_train_resampled, y_train_resampled)
train_acc_svm = accuracy_score(y_train_resampled, svm.predict(X_train_resampled))
test_acc_svm = accuracy_score(y_test, svm.predict(X_test))

"""### NB"""

nb = GaussianNB()
nb.fit(X_train_resampled, y_train_resampled)
train_acc_nb = accuracy_score(y_train_resampled, nb.predict(X_train_resampled))
test_acc_nb = accuracy_score(y_test, nb.predict(X_test))

"""### XGB"""

xgb_model = xgb.XGBClassifier(random_state=42)
xgb_model.fit(X_train_resampled, y_train_resampled)
train_acc_xgb = accuracy_score(y_train_resampled, xgb_model.predict(X_train_resampled))
test_acc_xgb = accuracy_score(y_test, xgb_model.predict(X_test))

"""## Evaluation

### Evaluasi sebelum dilakukan Hyperparameter
"""

# Inisialisasi DataFrame untuk menyimpan hasil
models = pd.DataFrame(index=['Train Accuracy', 'Test Accuracy'],
                     columns=['svm', 'RandomForest', 'NaiveBayes','xgb'])

# Masukkan hasil ke dalam DataFrame
models.loc['Train Accuracy', 'svm'] = train_acc_svm
models.loc['Test Accuracy', 'svm'] = test_acc_svm
models.loc['Train Accuracy', 'RandomForest'] = train_acc_rf
models.loc['Test Accuracy', 'RandomForest'] = test_acc_rf
models.loc['Train Accuracy', 'NaiveBayes'] = train_acc_nb
models.loc['Test Accuracy', 'NaiveBayes'] = test_acc_nb
models.loc['Test Accuracy', 'xgb'] = test_acc_xgb
models.loc['Train Accuracy', 'xgb'] = train_acc_xgb

# Menampilkan hasil
print(models)

"""Jika diperhatikan berdasarkan hasil akurasi untuk setiap model, tampak bahwa Model NB cenderung menjadi model yang akan dipilih. Karena model tersebut tampak dapat meng-generate data dengan baik dari pada model lainnya. Model lainnya terlihat mengalami overfitt jika dilihat dari hasil train dan test akurasi."""

print("\SVM Classification Report (Test Data):")
print(classification_report(y_test, svm.predict(X_test)))

"""Metrik Evaluasi Per Kelas:

Kelas 0 (Mayoritas)
- Precision: 0.85 : Dari semua prediksi sebagai kelas 0, 85% benar-benar termasuk kelas 0.
- Recall: 1.00 : Model berhasil mengidentifikasi semua sampel kelas 0 tanpa kesalahan.
- F1-Score: 0.92 : Menunjukkan keseimbangan yang sangat baik antara precision dan recall untuk kelas 0.
Wikipedia

Kelas 1 (Minoritas)
- Precision: 0.00 : Tidak ada prediksi yang benar untuk kelas 1; semua prediksi sebagai kelas 1 adalah salah.
- Recall: 0.00 : Model gagal mengidentifikasi sampel kelas 1; tidak ada sampel kelas 1 yang terdeteksi.

- F1-Score: 0.00 : Menunjukkan performa yang sangat buruk untuk kelas 1.
"""

print("\RF Classification Report (Test Data):")
print(classification_report(y_test, rf.predict(X_test)))

"""Metrik Evaluasi Per Kelas:

Kelas 0 (Mayoritas)
- Precision: 0.88 : Dari semua prediksi sebagai kelas 0, 88% benar-benar termasuk kelas 0.

- Recall: 0.92 : Model berhasil mengidentifikasi 92% dari semua sampel kelas 0.

- F1-Score: 0.90 : Menunjukkan keseimbangan yang sangat baik antara precision dan recall untuk kelas 0.

Kelas 1 (Minoritas)

- Precision: 0.41 : Dari semua prediksi sebagai kelas 1, hanya 41% yang benar-benar termasuk kelas 1.

- Recall: 0.30 : Model hanya berhasil mengidentifikasi 30% dari semua sampel kelas 1.

- F1-Score: 0.35 : Menunjukkan performa yang sangat buruk untuk kelas 1 karena rendahnya recall.


"""

print("\ NB Classification Report (Test Data):")
print(classification_report(y_test, nb.predict(X_test)))

""" Metrik Evaluasi Per Kelas:

- Kelas 0 (Mayoritas)

- Precision: 0.85 : Dari semua prediksi sebagai kelas 0, 85% benar-benar termasuk kelas 0.

- Recall: 1.00 : Model berhasil mengidentifikasi semua sampel kelas 0 tanpa kesalahan.

- F1-Score: 0.92 : Menunjukkan keseimbangan yang sangat baik antara precision dan recall untuk kelas 0.

Kelas 1 (Minoritas)

- Precision: 0.00 : Tidak ada prediksi yang benar untuk kelas 1; semua prediksi sebagai kelas 1 adalah salah.

- Recall: 0.00 : Model gagal mengidentifikasi sampel kelas 1; tidak ada sampel kelas 1 yang terdeteksi.

- F1-Score: 0.00 : Menunjukkan performa yang sangat buruk untuk kelas 1.


"""

print("\nXGBoost Classification Report (Test Data):")
print(classification_report(y_test, xgb_model.predict(X_test)))

"""Metrik Evaluasi Per Kelas:

- Kelas 0 (Mayoritas)

- Precision: 0.88 : Dari semua prediksi sebagai kelas 0, 88% benar-benar termasuk kelas 0.

- Recall: 0.73 : Model berhasil mengidentifikasi 73% dari semua sampel kelas 0.

- F1-Score: 0.80 : Menunjukkan keseimbangan yang baik antara precision dan recall untuk kelas 0.

Kelas 1 (Minoritas)

- Precision: 0.22 : Dari semua prediksi sebagai kelas 1, hanya 22% yang benar-benar termasuk kelas 1.

- Recall: 0.43 : Model berhasil mengidentifikasi 43% dari semua sampel kelas 1.

- F1-Score: 0.29 : Menunjukkan performa yang rendah untuk kelas 1, dengan precision dan recall yang sama-sama rendah.

Berdasarkan ketika Clasification report dari setiap model yang sudah dibuat. Dapat dilihat bahwa model yang lebih baik digunakan nantinya adalah XGBoost, hal ini dilihat dari perbandingan adengan algoritma lainnya, seperti algoritma NB dan SVM yang tidak dapat memprediksi dengan benar pada nilai 1. Dan pada model RF juga tampak kecil pada segi recall dalam memprediksi nilai benar (nilai 1) hanya 30% saja.

XGBoost terbilang lebih unggul dari algoritma lainnya walaupun prediksi benar belum maksimal.

#### Hyperparameter

Untuk mencoba meningkatkan akurasi pada model sebelumnya yang sudah dibuat, kita akan melakukan hyperparameter tuning pada setiap model menggunakan Bayesian Optimization. Tujuannya adalah mencari kombinasi parameter terbaik untuk meningkatkan performa prediksi berdasarkan nilai akurasi.
"""

pip install scikit-optimize

"""##### NB"""

from skopt import BayesSearchCV


rf = RandomForestClassifier(random_state=42)


search_space = {
    'n_estimators': (50, 500),
    'max_depth': (3, 30),
    'min_samples_split': (2, 20),
    'min_samples_leaf': (1, 20),
    'max_features': ['sqrt', 'log2']
}

opt = BayesSearchCV(
    estimator=rf,
    search_spaces=search_space,
    n_iter=32,
    scoring='accuracy',
    cv=5,
    random_state=42,
    n_jobs=-1
)


opt.fit(X_train_resampled, y_train_resampled)

print("Best parameters:", opt.best_params_)
print("Best cross-validation score:", opt.best_score_)

print("Test Accuracy:", opt.score(X_test, y_test))
print("Train Acc :", opt.score(X_train_resampled, y_train_resampled))

"""Tampak bahwa setelah dilakukan hyperparameter tuning, nilai Test dan Train mengalami peningkatakan, namun hal ini juga terjadi Overfitting pada model."""

nb = GaussianNB()

search_space_nb = {
    'var_smoothing': (1e-9, 1e-1, 'log-uniform')
}

opt_nb = BayesSearchCV(
    estimator=nb,
    search_spaces=search_space_nb,
    n_iter=32,
    scoring='accuracy',
    cv=5,
    random_state=42,
    n_jobs=-1
)


opt_nb.fit(X_train_resampled, y_train_resampled)

print("Best parameters for Naive Bayes:", opt_nb.best_params_)
print("Best cross-validation score:", opt_nb.best_score_)


print("Test Accuracy (Naive Bayes):", opt_nb.score(X_test, y_test))
print("Train Accuracy (Naive Bayes):", opt_nb.score(X_train_resampled, y_train_resampled))

"""Terjadinya peningkatan dari segi Akurasi terhadap data Test. Namin train test tidak mengalami peningkatan, dan tampak pula model dapat dikatakan baik dan tidak terjadi overfitt. Akan tetapi perlu dilihat juga informasai dari recall dan precision yang dihasilkan."""

svm = SVC(random_state=42)

search_space_svm = {
    'C': (0.1, 100, 'log-uniform'),
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': (1e-4, 1e-1, 'log-uniform'),
    'degree': (2, 5),
}

opt_svm = BayesSearchCV(
    estimator=svm,
    search_spaces=search_space_svm,
    n_iter=32,
    scoring='accuracy',
    cv=5,
    random_state=42,
    n_jobs=-1
)

opt_svm.fit(X_train_resampled, y_train_resampled)

print("Best parameters for SVM:", opt_svm.best_params_)
print("Best cross-validation score:", opt_svm.best_score_)

print("Test Accuracy (SVM):", opt_svm.score(X_test, y_test))
print("Train Accuracy (SVM):", opt_svm.score(X_train_resampled, y_train_resampled))

"""Dari hasil diatas tampak terjadinya peningkatan pada train dan test accuracy, namun jika diperhatikan hal ini juga terjadinya Overfitting pada model."""

from sklearn.model_selection import StratifiedKFold

# Inisialisasi model XGBoost
xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)

# Definisikan ruang pencarian hyperparameter
search_space = {
    'n_estimators': (50, 500),
    'max_depth': (3, 30),
    'learning_rate': (0.01, 0.3),
    'subsample': (0.5, 1.0),
    'colsample_bytree': (0.5, 1.0),
    'gamma': (0, 5),
    'reg_alpha': (0, 1),
    'reg_lambda': (0, 1)
}

# Inisialisasi BayesSearchCV
opt_xgb = BayesSearchCV(
    estimator=xgb_model,
    search_spaces=search_space,
    n_iter=32,
    scoring='accuracy',
    cv=StratifiedKFold(n_splits=5),
    random_state=42,
    n_jobs=-1,
    verbose=0
)

# Melatih model dengan data yang telah di-resample
opt_xgb.fit(X_train_resampled, y_train_resampled)

# Menampilkan hasil terbaik
print("Best parameters:", opt_xgb.best_params_)
print("Best cross-validation score:", opt_xgb.best_score_)

# Evaluasi pada data uji
print("Test Accuracy:", opt_xgb.score(X_test, y_test))
print("Train Accuracy:", opt_xgb.score(X_train_resampled, y_train_resampled))

"""Berdasarkan hasiil hyperparameter dari model XGBoost, model mengalami penurunan dari segi Training namun peningkatakan dari segi Akurasi pada Data Test. Hal ini tampak baik namun overfitting tetap terjadi."""

from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

# Prediksi untuk svm, Random Forest, dan Naive Bayes
y_pred_svm = opt_svm.predict(X_test)
y_pred_rf = opt.predict(X_test)
y_pred_nb = opt_nb.predict(X_test)
y_pred_xgb = opt_xgb.predict(X_test)

# Hitung confusion matrix untuk masing-masing model
cm_svm = confusion_matrix(y_test, y_pred_svm)
cm_rf = confusion_matrix(y_test, y_pred_rf)
cm_nb = confusion_matrix(y_test, y_pred_nb)
cm_xgb = confusion_matrix(y_test, y_pred_xgb)

print("svm Classification Report:")
print(classification_report(y_test, y_pred_svm))

print("Random Forest Classification Report:")
print(classification_report(y_test, y_pred_rf))

print("Naive Bayes Classification Report:")
print(classification_report(y_test, y_pred_nb))

print("XGB Classification Report:")
print(classification_report(y_test, y_pred_xgb))

"""Berdasarkan hasil classification report terhadap setiap model, dapat disimpulkan bahwa :
1. Algoritma Naive Bayes (NB) dan SVM memiliki akurasi keseluruhan yang tinggi (85%), namun performa terhadap kelas minoritas (kelas 1.0) sangat buruk. Hal ini terlihat dari nilai precision, recall, dan f1-score untuk kelas 1.0 yang semuanya 0.00, menunjukkan bahwa kedua model ini sama sekali tidak mampu mengklasifikasikan data kelas 1.0 dengan benar (underfitting terhadap kelas minoritas).
2. Algoritma Random Forest juga memiliki akurasi keseluruhan yang sama tinggi (85%), namun menunjukkan sedikit kemampuan dalam mengklasifikasikan kelas 1.0, dengan precision 0.43, recall 0.10, dan f1-score 0.16. Meskipun belum optimal, performanya lebih baik dari NB dan SVM dalam mendeteksi kelas minoritas.
3. Algoritma XGBoost memiliki akurasi keseluruhan yang sedikit lebih rendah (81%), namun memiliki keseimbangan performa yang lebih baik antara kedua kelas. Untuk kelas 1.0, nilai precision 0.37, recall 0.37, dan f1-score 0.37 menunjukkan bahwa XGBoost mampu mengenali sebagian data dari kelas minoritas, meskipun masih perlu perbaikan.

Kesimpulan :
1. Akurasi tinggi bukan satu-satunya indikator keberhasilan model, terutama dalam kasus klasifikasi dengan distribusi kelas yang tidak seimbang.

2. XGBoost dan Random Forest lebih layak dipertimbangkan dibandingkan SVM dan Naive Bayes karena masih mampu mengenali sebagian data kelas minoritas.

Berdasarkan hasil perbandingan diatas, dapat kita simpulkan bahwa algoritma yang lebih layak digunakan adalah XGBoost

# Menyimpan Model Terbaik

Model yang sudah dipilih selanjutnya akan disimpan kedalam formal pickle dan Dilakukan pengujian terhadap model prediksi.
"""

import pickle

with open("xgb_model.pkl", "wb") as f:
    pickle.dump(opt_xgb, f)

df_eda.to_csv('df_eda.csv', index=False)
files.download('df_eda.csv')

X_test.to_csv('X_test.csv', index = False)
files.download('X_test.csv')

y_test.to_csv('y_test.csv', index = False)
files.download('y_test.csv')

"""# Ujia coba model"""

with open("xgb_model.pkl", "rb") as f:
    loaded_model = pickle.load(f)


sample = X_test.iloc[[0]]  # ambil satu baris
print("Data sample untuk prediksi:")
print(sample)

print("Label asli:", y_test.iloc[0])

predicted = loaded_model.predict(sample)

print("Prediksi label:", predicted[0])

"""Berdasarkan hasil uji, Prediksi dilakukan terhadap data yang diambil dari data test. DIdapatkan hasil prediksi nya sesuai dengan data sample yang diambil yaitu dengan label 0."""

!pip freeze > requirements.txt

files.download("requirements.txt")

